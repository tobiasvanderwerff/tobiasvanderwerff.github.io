---
layout: post
title: "The Age of AI-Powered Curiosity"
tags: essay
---

When I was a kid, I used to ask my mother all kinds of questions about the world, asking things like *Why is the sky blue?* or *Why does the sun disappear at night?* Although my mother is a patient woman, she would usually get tired of my never-ending stream of *why* questions pretty quickly. Usually, this meant that she would shut down the conversation with a simple "because that's just how it is".

Obviously my mom is not to blame for not knowing every single random fact I was interested in at that age. Since I could not find most of the answers I was looking for, I remember fantasizing about having a magical electronic device -- a handheld device, like a Game Boy -- that could answer all my questions about the world. I would simply type in a question and get the answer back from the device. No subject would be off limits. Such an oracle of knowledge seemed to me like true magic, and I never seriously considered that such a device could actually exist.

But the magical technology I dreamt of as a kid actually exists in the world we live in today.

## Enter LLMs

What I envisioned then exists today in the form of large language models -- extremely large neural networks trained on massive amounts of internet data. This training has given these models vast knowledge of the world. To the degree that information can be found on the internet, LLMs have memorized it. The addition of RLHF (Reinforcement Learning from Human Feedback) has made interaction with these models as accessible as having a conversation with another person. The result is nothing short of spectacular, and I believe the world has yet to realize the true potential of this technology.

One of my favorite use cases for LLMs in day-to-day life is to use them as a tool for exploration and curiosity-based research. This can be for the purpose of [solving a concrete problem](https://tobiasvanderwerff.github.io/2024/06/17/useful-knowledge.html), or just being curious about how things work and wanting to dive deeper. For instance, I recently found myself wondering about several questions:

- "Why does money become worth less over time?"
- "What makes kerosone suitable for airplane fuel?"
- "Why don't we have electric airplanes?"
 
If you were to do an internet search, especially for very specific questions, you would typically need some time to find a good answer. However, these days, I simply ask an LLM:

<figure>
    <img class="center" src="/assets/images/ai-powered-curiosity/electric-airplanes.png" alt="A conversation with Claude 3.5 Sonnet about electric airplanes.">
    <figcaption>
    Claude 3.5 Sonnet answering my random questions about the world. Source: Perplexity.
    </figcaption>
</figure>

The best part: I can get answers to questions like this in a matter of seconds. I'm only limited by my typing speed, or I can even state my questions out loud by using text-to-speech on most LLM providers. One of the absolute best parts about this is that you can ask as many detailed follow-up questions as you want. Learning becomes *personalized*, since we can all ask the questions we personally find most interesting. Above all, this makes learning so much more *fun*. With an LLM assistant, you can have an incredibly short feedback loop that allows you to dive into any aspect of the answer you find most interesting.

This short feedback loop is in stark contrast to how information used to be accessed for most of human history. If we think about the evolution of the speed of information retrieval, I imagine it would have gone something like this:

| Era                              | Method of Information Retrieval               | Estimated Time |
| -------------------------        | --------------------------------------------- | -------------- |
| Pre-Printing Press (before 1450) | Find an expert human to answer your question  | Weeks-years    |
| Print Era (1450-1990)            | Search through books                          | Hours-days     |
| Internet Age (Post-2000s)        | Google search and browse websites             | Minutes        |
| AI Age (2020-present)            | Ask an LLM                                    | Seconds        |

What this means is that access to information used to be highly dependent on your geographical location, whereas in current times, all you need is an internet connection and a few seconds of your time! Furthermore, in the age of AI, the quality of the information retrieval will also be higher, since answers are synthesized directly based on questions.[^1]

Finally -- and this might sound a bit silly --, I think another great aspect of LLMs is that they don't judge you. I imagine most people can relate to the feeling of not asking certain basic questions because we don't want to appear [dumb](https://danluu.com/look-stupid/) or ignorant. With an AI assistant, this is not a problem -- it can be as patient and as compassionate as you want it to be, and it won't judge you in any way. This makes it easier for me to ask questions I'm curious about, no matter how basic they might be.

## It's still early days

There tends to be lots of talk about the progress of AI in years to come. However, there might not be enough appreciation of what AI can already do for us today. I imagine a similar thing happened back when the internet was invented. Wikipedia founder Jimmy Wales noted that the technical capability for an online encyclopedia existed well before its creation. The breakthrough wasn't technological -- it was conceptual, requiring a shift in thinking about collaborative content creation. Similarly, even if AI were to stay at exactly the same level as it is today, we will still find lots of applications for it that will make all of our lives better. In other words, we are still in the early stages of figuring out how to effectively use this weird new technology.

Hallucinations are another aspect that tend to be brought up as a major obstacle for making LLMs useful. However, I think this is not as relevant for exploratory questions like the ones I mentioned earlier. If you ask an LLM about well-established topics or factual matters, it tends to do fine 99% of the time. Moreover, hallucination tends to be more of an issue for smaller models, whereas the frontier models (like ChatGPT 4, or Claude 3.5) suffer much less from this problem. Additionally, if you use a service like [Perplexity](https://perplexity.ai) for web search (which I use every day), you can simply check the cited sources for verification.


## Conclusion

Working with LLMs is like working with alien technology -- there's no manual for it. So it's always important to keep a critical mindset when evaluating an LLMs output. But with some training and awareness of how LLMs function, I believe there's hardly a limit to how useful they can be.

LLMs have helped me regain some of the sense of wonder I used to have as a kid when I pestered my mother with random questions about the universe. Learning doesn't have to be boring, and LLMs are making this abundantly clear. We are truly at the beginning of a new age of curiosity, and I'm looking forward to all the incredible applications that AI will make possible.

## Related reading

- [Tyler Cowen: How to read a book using o1](https://marginalrevolution.com/marginalrevolution/2024/12/how-to-read-a-book-using-o1.html)


---
<br>

[^1]: The way I sometimes try to explain this is that it's like having a superhuman friend who has memorized the internet, whom you can directly ask any question.
